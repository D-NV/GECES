{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emotions1=[\"Happy\",\"Sad\",\"Amused\",\"Tender\",\"Angry\",\"Scared\",\"Disgusted\",\"Neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emotions=[\"Happy\",\"Sad\",\"Amused\",\"Tender\",\"Angry\",\"Scared\",\"Disgusted\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy\n",
      "(1763, 39)\n",
      "Sad\n",
      "(1991, 39)\n",
      "Amused\n",
      "(2022, 39)\n",
      "Tender\n",
      "(1662, 39)\n",
      "Angry\n",
      "(2448, 39)\n",
      "Scared\n",
      "(884, 39)\n",
      "Disgusted\n",
      "(1674, 39)\n"
     ]
    }
   ],
   "source": [
    "for emotion in emotions:\n",
    "        print(emotion)\n",
    "        d = {name: pd.DataFrame() for name in emotions}\n",
    "        path2=f\"U:\\\\Semester 7\\\\Capstone\\\\Emotions\\\\Extracted {emotion}\\\\\"\n",
    "        #print(path2)\n",
    "        for root, dirs, files in os.walk(path2):\n",
    "#             df1 = pd.Dataframe\n",
    "            for filename in files:\n",
    "#                 print(filename)\n",
    "                df2=pd.read_csv(path2+filename,sep=',', skip_blank_lines=True)\n",
    "#                 print(np.array(df2).shape)\n",
    "                d[emotion] = pd.concat([d[emotion], df2])\n",
    "            print(np.array(d[emotion]).shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy\n",
      "U:\\Semester 7\\Capstone\\Emotions\\Finalcsvs\\Happy.csv\n",
      "(1763, 38)\n",
      "(1174, 37)\n",
      "Sad\n",
      "U:\\Semester 7\\Capstone\\Emotions\\Finalcsvs\\Sad.csv\n",
      "(1991, 38)\n",
      "(1338, 37)\n",
      "Amused\n",
      "U:\\Semester 7\\Capstone\\Emotions\\Finalcsvs\\Amused.csv\n",
      "(2022, 38)\n",
      "(1398, 37)\n",
      "Tender\n",
      "U:\\Semester 7\\Capstone\\Emotions\\Finalcsvs\\Tender.csv\n",
      "(1662, 38)\n",
      "(1115, 37)\n",
      "Angry\n",
      "U:\\Semester 7\\Capstone\\Emotions\\Finalcsvs\\Angry.csv\n",
      "(2448, 38)\n",
      "(1556, 37)\n",
      "Scared\n",
      "U:\\Semester 7\\Capstone\\Emotions\\Finalcsvs\\Scared.csv\n",
      "(884, 38)\n",
      "(519, 37)\n",
      "Disgusted\n",
      "U:\\Semester 7\\Capstone\\Emotions\\Finalcsvs\\Disgusted.csv\n",
      "(1674, 38)\n",
      "(1007, 37)\n"
     ]
    }
   ],
   "source": [
    "for emotion in emotions:\n",
    "        print(emotion)\n",
    "        d = {name: pd.DataFrame() for name in emotions}\n",
    "        path2=f\"U:\\\\Semester 7\\\\Capstone\\\\Emotions\\\\Extracted {emotion}\\\\\"\n",
    "        #print(path2)\n",
    "        for root, dirs, files in os.walk(path2):\n",
    "#             df1 = pd.Dataframe\n",
    "            for filename in files:\n",
    "#                 print(filename)\n",
    "                df2=pd.read_csv(path2+filename,sep=',', skip_blank_lines=True, header=0, index_col=0)\n",
    "#                 print(np.array(df2).shape)\n",
    "                d[emotion] = pd.concat([d[emotion], df2])\n",
    "            \n",
    "        export_file_path = \"U:\\\\Semester 7\\\\Capstone\\\\Emotions\\\\Finalcsvs\\\\\"\n",
    "        csvfilename=f\"{emotion}.csv\"\n",
    "        print(export_file_path+csvfilename)\n",
    "        newpath=export_file_path+csvfilename\n",
    "        print(np.array(d[emotion]).shape)\n",
    "        d[emotion]=d[emotion].iloc[:,:-1].dropna()\n",
    "        print(np.array(d[emotion]).shape)\n",
    "        d[emotion].to_csv(newpath, index = None, header=True)\n",
    "#         print(d[emotion].head(80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Delta_AF7  Delta_AF8  Delta_TP10  Theta_TP9  Theta_AF7  Theta_AF8  \\\n",
      "Delta_TP9                                                                      \n",
      " 0.540034   0.803615  -0.263441    0.168931   0.159531   0.356520  -0.295784   \n",
      " 0.149771   0.253535   0.578154    0.606145   0.009796   0.212852  -0.064238   \n",
      "-0.066366  -0.453483  -0.069380    0.105457  -0.193809  -0.402539   0.003401   \n",
      " 0.218026   0.000000   0.467383    0.888921   0.095387   0.000000   0.089932   \n",
      " 0.971143   0.613813   0.366377    0.991649   0.733046  -0.047291   0.050081   \n",
      " 0.676671   0.680080   0.656523    0.803457   0.182391  -0.124810   0.418654   \n",
      " 0.213173   0.000000   0.292700    0.282793   0.711423   0.000000   0.444640   \n",
      " 0.323069   0.215630   0.675818    0.699674   0.151315  -0.718794   0.402615   \n",
      " 0.963676  -0.584777   0.221903    0.302150   0.558278  -0.763722   0.182198   \n",
      " 1.318964   0.022107   0.446671    1.532767   1.606674   0.176633   0.029063   \n",
      "-3.198223   0.585866   0.147618    1.055047  -3.141619   0.388110  -0.180329   \n",
      " 0.365441   0.000000   1.001759    0.212007   0.697192   0.000000   0.430171   \n",
      " 0.918767   0.448193   0.419216    0.984369   0.175284   0.548527   0.307808   \n",
      " 0.411681   0.196430   0.416002    0.583321   0.300464  -0.072520  -0.393444   \n",
      " 1.432752   0.692926   0.708925    0.351733   0.946131   0.495369   0.739958   \n",
      " 0.718750   0.558745   0.527176    0.657075   0.348314   0.365544   0.420508   \n",
      " 0.487070   0.000000  -0.415245    0.435185   0.490844   0.000000  -0.265079   \n",
      " 0.056968   0.211855   0.974965    0.291571   0.473342   0.379526   1.013598   \n",
      " 0.357012   0.014308   0.472337    0.535962  -0.004001  -0.215976   0.101194   \n",
      " 0.487026   0.000000   0.000000    0.276477   0.488548   0.000000   0.000000   \n",
      " 0.663098   0.730942   0.313637    0.482088   0.311050   0.777058   0.175257   \n",
      " 0.526629   1.005615   0.954518    0.333834   0.497046  -0.224240   0.912116   \n",
      " 0.531769   1.041777   0.788743   -0.456831   0.814564   0.647147   0.559334   \n",
      " 0.225120  -0.147522   1.095568    0.788109   0.535690  -0.093300   1.034610   \n",
      " 0.481116   0.000000   0.292700    0.541598   0.781289   0.000000   0.444640   \n",
      "\n",
      "           Theta_TP10  Alpha_TP9  Alpha_AF7  Alpha_AF8    ...      Beta_TP10  \\\n",
      "Delta_TP9                                                 ...                  \n",
      " 0.540034    0.210762   0.718441   0.107953   0.286740    ...       0.902186   \n",
      " 0.149771    0.429435   0.221751  -0.130791   0.468704    ...       0.597081   \n",
      "-0.066366    0.145561   0.822553   0.098947   0.281481    ...       0.486049   \n",
      " 0.218026    0.844171   0.311854   0.000000   0.322353    ...       0.800579   \n",
      " 0.971143    0.794498   1.200492   0.185769   0.173454    ...       0.819066   \n",
      " 0.676671    0.252183   0.710622  -0.028109   0.414571    ...       0.514306   \n",
      " 0.213173    0.677217   0.842879   0.000000   0.387306    ...       0.528343   \n",
      " 0.323069    0.740568   0.592953   0.073890   0.507593    ...       0.973163   \n",
      " 0.963676    0.437109   0.668945  -0.325872   0.270021    ...       0.274723   \n",
      " 1.318964    1.523138   1.586775   0.407694   0.146612    ...       0.845428   \n",
      "-3.198223    0.887871  -2.738614   0.564657   0.076474    ...       0.489032   \n",
      " 0.365441    0.567525   0.649526   0.000000  -0.005612    ...       0.440359   \n",
      " 0.918767    0.485305   0.721031   0.503068   0.950567    ...       0.725878   \n",
      " 0.411681    0.344040   0.848451  -0.073310   0.163474    ...       0.119499   \n",
      " 1.432752    0.411359   0.828658   0.805521   0.891976    ...       1.040896   \n",
      " 0.718750    0.662045   0.804688   0.411531   0.520071    ...       0.397905   \n",
      " 0.487070    0.475885   0.976564   0.000000  -0.074563    ...       0.586418   \n",
      " 0.056968    0.600822   0.528729   0.553123   1.214852    ...       0.975156   \n",
      " 0.357012    0.195486   0.245991   0.284263   0.357514    ...       0.632563   \n",
      " 0.487026    0.183506   0.791690   0.000000   0.000000    ...       0.574950   \n",
      " 0.663098    0.658292   0.827657   0.693830   0.195481    ...       0.528057   \n",
      " 0.526629    0.679145   0.568480   0.057895   0.784356    ...       0.259321   \n",
      " 0.531769    0.453286   0.866814   0.601203   0.316019    ...       1.000487   \n",
      " 0.225120    0.669735   0.990046   0.214001   0.875288    ...       0.898597   \n",
      " 0.481116    0.567644   0.624123   0.000000   0.387306    ...       0.321507   \n",
      "\n",
      "           Gamma_TP9  Gamma_AF7  Gamma_AF8  Gamma_TP10    RAW_TP9     RAW_AF7  \\\n",
      "Delta_TP9                                                                       \n",
      " 0.540034   0.655396   0.249737   0.410515    0.371228  863.47986   866.30035   \n",
      " 0.149771   0.255251  -0.554928   0.434432    0.476996  807.87550   747.83880   \n",
      "-0.066366   0.224205   0.857623   0.603281    0.177965  823.18680   788.93774   \n",
      " 0.218026  -0.262106   0.000000   0.355486    0.454008  804.24910  1130.21970   \n",
      " 0.971143   0.448506   0.063187   0.458826    1.002911  819.56040   784.10254   \n",
      " 0.676671   0.241685  -0.361572  -0.172194    0.374023  812.71063   915.86080   \n",
      " 0.213173   0.739228   0.000000  -0.169691    0.269688  763.15020   862.67400   \n",
      " 0.323069   0.803525   0.263728  -0.076880    0.821955  796.99634   780.47620   \n",
      " 0.963676   0.789660  -0.151043  -0.383720    0.133214  831.24540   809.89014   \n",
      " 1.318964   0.329852   1.003507   0.109267    0.162069  811.90480   806.66670   \n",
      "-3.198223  -2.644557  -0.107194  -0.060931    0.202356  735.75090   741.39197   \n",
      " 0.365441   0.506618   0.000000  -0.038395   -0.015463  838.49817   581.42860   \n",
      " 0.918767   0.383719   0.069215   0.492643    0.327247  798.20514   775.23810   \n",
      " 0.411681   0.904328  -0.077774  -0.501194    0.047105  818.75460   795.78754   \n",
      " 1.432752   0.488659   0.405288   0.503926    1.185380  769.59705   804.65204   \n",
      " 0.718750  -0.008378  -0.060147  -0.102181   -0.022893  800.21980   840.91580   \n",
      " 0.487070   0.292501   0.000000  -0.499837    0.222037  756.30035   936.81320   \n",
      " 0.056968   0.650653   0.488998   0.154784    0.828874  801.02563   786.11720   \n",
      " 0.357012   0.264747  -0.074426  -0.319983    0.058731  784.10254   790.14655   \n",
      " 0.487026   0.247701   0.000000   0.000000    0.261872  795.78754  1018.60803   \n",
      " 0.663098   0.419827  -0.009557   0.083650    0.441265  781.28204   795.38464   \n",
      " 0.526629   0.078668  -0.781721  -0.118701    0.073226  805.86080   908.20514   \n",
      " 0.531769   1.514561  -0.355864   0.054773    1.180761  830.43960   805.86080   \n",
      " 0.225120   0.436874   0.643182  -0.230484    0.776700  803.04030   803.44324   \n",
      " 0.481116   0.762541   0.000000  -0.169691    0.261460  444.83517     0.00000   \n",
      "\n",
      "              RAW_AF8   RAW_TP10    Emotion  \n",
      "Delta_TP9                                    \n",
      " 0.540034   806.66670  865.09155        Sad  \n",
      " 0.149771   780.47620  790.14655  Disgusted  \n",
      "-0.066366   781.28204  821.57510      Happy  \n",
      " 0.218026  1031.50180  793.36993        Sad  \n",
      " 0.971143   802.63740  786.11720     Amused  \n",
      " 0.676671   761.53845  832.85710    Neutral  \n",
      " 0.213173   890.07324  800.62270     Tender  \n",
      " 0.323069   794.98170  796.99634     Amused  \n",
      " 0.963676   801.02563  799.81683    Neutral  \n",
      " 1.318964   795.78754  844.54210    Neutral  \n",
      "-3.198223   776.44690  364.65200    Neutral  \n",
      " 0.365441   721.24540  765.97070      Happy  \n",
      " 0.918767   782.89380  780.07324    Neutral  \n",
      " 0.411681   809.48720  808.27840        Sad  \n",
      " 1.432752   799.01100  761.94140     Tender  \n",
      " 0.718750   802.23444  794.57874    Neutral  \n",
      " 0.487070   805.86080  743.80950    Neutral  \n",
      " 0.056968   790.54944  810.69600     Tender  \n",
      " 0.357012   804.65204  792.56410      Angry  \n",
      " 0.487026  1015.78754  807.87550     Tender  \n",
      " 0.663098   796.99634  796.19050        Sad  \n",
      " 0.526629   799.41394  822.78390    Neutral  \n",
      " 0.531769   782.49084  788.53480     Tender  \n",
      " 0.225120   802.63740  819.15753    Neutral  \n",
      " 0.481116   849.78020  514.13920     Tender  \n",
      "\n",
      "[25 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.DataFrame() \n",
    "path2=f\"U:\\\\Semester 7\\\\Capstone\\\\Emotions\\\\Finalcsvs\\\\\"\n",
    "#print(path2)\n",
    "for root, dirs, files in os.walk(path2):\n",
    "#             df1 = pd.Dataframe\n",
    "    for filename in files:\n",
    "        \n",
    "        #print(filename)\n",
    "        df2=pd.read_csv(path2+filename,sep=',', skip_blank_lines=True, header=0, index_col=0)\n",
    "        df2[\"Emotion\"]=filename[:-4]\n",
    "        #print(df2.head())\n",
    "#                 print(np.array(df2).shape)\n",
    "        data = pd.concat([data, df2])\n",
    "\n",
    "export_file_path = \"U:\\\\Semester 7\\\\Capstone\\\\Emotions\\\\\"\n",
    "\n",
    "csvfilename=\"Allfeatures.csv\"\n",
    "# print(export_file_path+csvfilename)\n",
    "newpath=export_file_path+csvfilename\n",
    "# print(np.array(d[emotion]).shape)\n",
    "# d[emotion]=d[emotion].iloc[:,:-1].dropna()\n",
    "# print(np.array(d[emotion]).shape)\n",
    "data = data.drop(\"Battery\", axis=1)\n",
    "data = data.drop(\"HeadBandOn\", axis=1)\n",
    "data = data.drop(\"Gyro_X\", axis=1)\n",
    "data = data.drop(\"Gyro_Y\", axis=1)\n",
    "data = data.drop(\"Gyro_Z\", axis=1)\n",
    "data = data.drop(\"HSI_TP9\", axis=1)\n",
    "data = data.drop(\"HSI_TP10\", axis=1)\n",
    "data = data.drop(\"HSI_AF7\", axis=1)\n",
    "data = data.drop(\"HSI_AF8\", axis=1)\n",
    "data = data.drop(\"AUX_RIGHT\", axis=1)\n",
    "data = data.drop(\"Accelerometer_X\", axis=1)\n",
    "data = data.drop(\"Accelerometer_Z\", axis=1)\n",
    "data = data.drop(\"Accelerometer_Y\", axis=1)\n",
    "data=data.sample(frac=1)\n",
    "print(data.head(25))\n",
    "\n",
    "data.to_csv(newpath, index = None, header=True)\n",
    "# #         print(d[emotion].head(80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delta_TP9\n",
       " 0.540034          Sad\n",
       " 0.149771    Disgusted\n",
       "-0.066366        Happy\n",
       " 0.218026          Sad\n",
       " 0.971143       Amused\n",
       " 0.676671      Neutral\n",
       " 0.213173       Tender\n",
       " 0.323069       Amused\n",
       " 0.963676      Neutral\n",
       " 1.318964      Neutral\n",
       "-3.198223      Neutral\n",
       " 0.365441        Happy\n",
       " 0.918767      Neutral\n",
       " 0.411681          Sad\n",
       " 1.432752       Tender\n",
       " 0.718750      Neutral\n",
       " 0.487070      Neutral\n",
       " 0.056968       Tender\n",
       " 0.357012        Angry\n",
       " 0.487026       Tender\n",
       " 0.663098          Sad\n",
       " 0.526629      Neutral\n",
       " 0.531769       Tender\n",
       " 0.225120      Neutral\n",
       " 0.481116       Tender\n",
       " 0.230538      Neutral\n",
       " 0.389395        Happy\n",
       "-3.568150      Neutral\n",
       " 0.081728        Angry\n",
       " 0.111698      Neutral\n",
       "               ...    \n",
       " 0.878025          Sad\n",
       " 0.921296        Happy\n",
       " 0.877619        Angry\n",
       "-0.404254        Angry\n",
       " 0.048582       Scared\n",
       " 1.050515      Neutral\n",
       " 0.818705          Sad\n",
       " 0.733242      Neutral\n",
       "-3.568150      Neutral\n",
       " 0.543511        Angry\n",
       " 0.578504        Happy\n",
       " 1.140964      Neutral\n",
       " 0.501428       Tender\n",
       " 0.826584       Tender\n",
       "-0.283943    Disgusted\n",
       " 0.137270          Sad\n",
       " 0.480742      Neutral\n",
       " 0.834978      Neutral\n",
       "-0.032912       Amused\n",
       " 0.416303        Angry\n",
       " 0.737815       Amused\n",
       "-0.085366       Tender\n",
       " 0.257929       Tender\n",
       " 0.451732      Neutral\n",
       " 0.553063          Sad\n",
       "-0.094362          Sad\n",
       " 0.432693    Disgusted\n",
       " 0.446872       Amused\n",
       "-3.198223      Neutral\n",
       " 0.580014        Happy\n",
       "Name: Emotion, Length: 11540, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data.iloc[:,-1]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Delta_AF7</th>\n",
       "      <th>Delta_AF8</th>\n",
       "      <th>Delta_TP10</th>\n",
       "      <th>Theta_TP9</th>\n",
       "      <th>Theta_AF7</th>\n",
       "      <th>Theta_AF8</th>\n",
       "      <th>Theta_TP10</th>\n",
       "      <th>Alpha_TP9</th>\n",
       "      <th>Alpha_AF7</th>\n",
       "      <th>Alpha_AF8</th>\n",
       "      <th>...</th>\n",
       "      <th>Beta_AF8</th>\n",
       "      <th>Beta_TP10</th>\n",
       "      <th>Gamma_TP9</th>\n",
       "      <th>Gamma_AF7</th>\n",
       "      <th>Gamma_AF8</th>\n",
       "      <th>Gamma_TP10</th>\n",
       "      <th>RAW_TP9</th>\n",
       "      <th>RAW_AF7</th>\n",
       "      <th>RAW_AF8</th>\n",
       "      <th>RAW_TP10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delta_TP9</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.540034</th>\n",
       "      <td>0.803615</td>\n",
       "      <td>-0.263441</td>\n",
       "      <td>0.168931</td>\n",
       "      <td>0.159531</td>\n",
       "      <td>0.356520</td>\n",
       "      <td>-0.295784</td>\n",
       "      <td>0.210762</td>\n",
       "      <td>0.718441</td>\n",
       "      <td>0.107953</td>\n",
       "      <td>0.286740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.581179</td>\n",
       "      <td>0.902186</td>\n",
       "      <td>0.655396</td>\n",
       "      <td>0.249737</td>\n",
       "      <td>0.410515</td>\n",
       "      <td>0.371228</td>\n",
       "      <td>863.47986</td>\n",
       "      <td>866.30035</td>\n",
       "      <td>806.66670</td>\n",
       "      <td>865.09155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.149771</th>\n",
       "      <td>0.253535</td>\n",
       "      <td>0.578154</td>\n",
       "      <td>0.606145</td>\n",
       "      <td>0.009796</td>\n",
       "      <td>0.212852</td>\n",
       "      <td>-0.064238</td>\n",
       "      <td>0.429435</td>\n",
       "      <td>0.221751</td>\n",
       "      <td>-0.130791</td>\n",
       "      <td>0.468704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875127</td>\n",
       "      <td>0.597081</td>\n",
       "      <td>0.255251</td>\n",
       "      <td>-0.554928</td>\n",
       "      <td>0.434432</td>\n",
       "      <td>0.476996</td>\n",
       "      <td>807.87550</td>\n",
       "      <td>747.83880</td>\n",
       "      <td>780.47620</td>\n",
       "      <td>790.14655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.066366</th>\n",
       "      <td>-0.453483</td>\n",
       "      <td>-0.069380</td>\n",
       "      <td>0.105457</td>\n",
       "      <td>-0.193809</td>\n",
       "      <td>-0.402539</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.145561</td>\n",
       "      <td>0.822553</td>\n",
       "      <td>0.098947</td>\n",
       "      <td>0.281481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.609252</td>\n",
       "      <td>0.486049</td>\n",
       "      <td>0.224205</td>\n",
       "      <td>0.857623</td>\n",
       "      <td>0.603281</td>\n",
       "      <td>0.177965</td>\n",
       "      <td>823.18680</td>\n",
       "      <td>788.93774</td>\n",
       "      <td>781.28204</td>\n",
       "      <td>821.57510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.218026</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.467383</td>\n",
       "      <td>0.888921</td>\n",
       "      <td>0.095387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089932</td>\n",
       "      <td>0.844171</td>\n",
       "      <td>0.311854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.322353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.872978</td>\n",
       "      <td>0.800579</td>\n",
       "      <td>-0.262106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355486</td>\n",
       "      <td>0.454008</td>\n",
       "      <td>804.24910</td>\n",
       "      <td>1130.21970</td>\n",
       "      <td>1031.50180</td>\n",
       "      <td>793.36993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.971143</th>\n",
       "      <td>0.613813</td>\n",
       "      <td>0.366377</td>\n",
       "      <td>0.991649</td>\n",
       "      <td>0.733046</td>\n",
       "      <td>-0.047291</td>\n",
       "      <td>0.050081</td>\n",
       "      <td>0.794498</td>\n",
       "      <td>1.200492</td>\n",
       "      <td>0.185769</td>\n",
       "      <td>0.173454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771983</td>\n",
       "      <td>0.819066</td>\n",
       "      <td>0.448506</td>\n",
       "      <td>0.063187</td>\n",
       "      <td>0.458826</td>\n",
       "      <td>1.002911</td>\n",
       "      <td>819.56040</td>\n",
       "      <td>784.10254</td>\n",
       "      <td>802.63740</td>\n",
       "      <td>786.11720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.676671</th>\n",
       "      <td>0.680080</td>\n",
       "      <td>0.656523</td>\n",
       "      <td>0.803457</td>\n",
       "      <td>0.182391</td>\n",
       "      <td>-0.124810</td>\n",
       "      <td>0.418654</td>\n",
       "      <td>0.252183</td>\n",
       "      <td>0.710622</td>\n",
       "      <td>-0.028109</td>\n",
       "      <td>0.414571</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006982</td>\n",
       "      <td>0.514306</td>\n",
       "      <td>0.241685</td>\n",
       "      <td>-0.361572</td>\n",
       "      <td>-0.172194</td>\n",
       "      <td>0.374023</td>\n",
       "      <td>812.71063</td>\n",
       "      <td>915.86080</td>\n",
       "      <td>761.53845</td>\n",
       "      <td>832.85710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.213173</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292700</td>\n",
       "      <td>0.282793</td>\n",
       "      <td>0.711423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444640</td>\n",
       "      <td>0.677217</td>\n",
       "      <td>0.842879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.387306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191733</td>\n",
       "      <td>0.528343</td>\n",
       "      <td>0.739228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.169691</td>\n",
       "      <td>0.269688</td>\n",
       "      <td>763.15020</td>\n",
       "      <td>862.67400</td>\n",
       "      <td>890.07324</td>\n",
       "      <td>800.62270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.323069</th>\n",
       "      <td>0.215630</td>\n",
       "      <td>0.675818</td>\n",
       "      <td>0.699674</td>\n",
       "      <td>0.151315</td>\n",
       "      <td>-0.718794</td>\n",
       "      <td>0.402615</td>\n",
       "      <td>0.740568</td>\n",
       "      <td>0.592953</td>\n",
       "      <td>0.073890</td>\n",
       "      <td>0.507593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062287</td>\n",
       "      <td>0.973163</td>\n",
       "      <td>0.803525</td>\n",
       "      <td>0.263728</td>\n",
       "      <td>-0.076880</td>\n",
       "      <td>0.821955</td>\n",
       "      <td>796.99634</td>\n",
       "      <td>780.47620</td>\n",
       "      <td>794.98170</td>\n",
       "      <td>796.99634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.963676</th>\n",
       "      <td>-0.584777</td>\n",
       "      <td>0.221903</td>\n",
       "      <td>0.302150</td>\n",
       "      <td>0.558278</td>\n",
       "      <td>-0.763722</td>\n",
       "      <td>0.182198</td>\n",
       "      <td>0.437109</td>\n",
       "      <td>0.668945</td>\n",
       "      <td>-0.325872</td>\n",
       "      <td>0.270021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148604</td>\n",
       "      <td>0.274723</td>\n",
       "      <td>0.789660</td>\n",
       "      <td>-0.151043</td>\n",
       "      <td>-0.383720</td>\n",
       "      <td>0.133214</td>\n",
       "      <td>831.24540</td>\n",
       "      <td>809.89014</td>\n",
       "      <td>801.02563</td>\n",
       "      <td>799.81683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.318964</th>\n",
       "      <td>0.022107</td>\n",
       "      <td>0.446671</td>\n",
       "      <td>1.532767</td>\n",
       "      <td>1.606674</td>\n",
       "      <td>0.176633</td>\n",
       "      <td>0.029063</td>\n",
       "      <td>1.523138</td>\n",
       "      <td>1.586775</td>\n",
       "      <td>0.407694</td>\n",
       "      <td>0.146612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051140</td>\n",
       "      <td>0.845428</td>\n",
       "      <td>0.329852</td>\n",
       "      <td>1.003507</td>\n",
       "      <td>0.109267</td>\n",
       "      <td>0.162069</td>\n",
       "      <td>811.90480</td>\n",
       "      <td>806.66670</td>\n",
       "      <td>795.78754</td>\n",
       "      <td>844.54210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-3.198223</th>\n",
       "      <td>0.585866</td>\n",
       "      <td>0.147618</td>\n",
       "      <td>1.055047</td>\n",
       "      <td>-3.141619</td>\n",
       "      <td>0.388110</td>\n",
       "      <td>-0.180329</td>\n",
       "      <td>0.887871</td>\n",
       "      <td>-2.738614</td>\n",
       "      <td>0.564657</td>\n",
       "      <td>0.076474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043047</td>\n",
       "      <td>0.489032</td>\n",
       "      <td>-2.644557</td>\n",
       "      <td>-0.107194</td>\n",
       "      <td>-0.060931</td>\n",
       "      <td>0.202356</td>\n",
       "      <td>735.75090</td>\n",
       "      <td>741.39197</td>\n",
       "      <td>776.44690</td>\n",
       "      <td>364.65200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.365441</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.001759</td>\n",
       "      <td>0.212007</td>\n",
       "      <td>0.697192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430171</td>\n",
       "      <td>0.567525</td>\n",
       "      <td>0.649526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073163</td>\n",
       "      <td>0.440359</td>\n",
       "      <td>0.506618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.038395</td>\n",
       "      <td>-0.015463</td>\n",
       "      <td>838.49817</td>\n",
       "      <td>581.42860</td>\n",
       "      <td>721.24540</td>\n",
       "      <td>765.97070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.918767</th>\n",
       "      <td>0.448193</td>\n",
       "      <td>0.419216</td>\n",
       "      <td>0.984369</td>\n",
       "      <td>0.175284</td>\n",
       "      <td>0.548527</td>\n",
       "      <td>0.307808</td>\n",
       "      <td>0.485305</td>\n",
       "      <td>0.721031</td>\n",
       "      <td>0.503068</td>\n",
       "      <td>0.950567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572322</td>\n",
       "      <td>0.725878</td>\n",
       "      <td>0.383719</td>\n",
       "      <td>0.069215</td>\n",
       "      <td>0.492643</td>\n",
       "      <td>0.327247</td>\n",
       "      <td>798.20514</td>\n",
       "      <td>775.23810</td>\n",
       "      <td>782.89380</td>\n",
       "      <td>780.07324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.411681</th>\n",
       "      <td>0.196430</td>\n",
       "      <td>0.416002</td>\n",
       "      <td>0.583321</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>-0.072520</td>\n",
       "      <td>-0.393444</td>\n",
       "      <td>0.344040</td>\n",
       "      <td>0.848451</td>\n",
       "      <td>-0.073310</td>\n",
       "      <td>0.163474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010701</td>\n",
       "      <td>0.119499</td>\n",
       "      <td>0.904328</td>\n",
       "      <td>-0.077774</td>\n",
       "      <td>-0.501194</td>\n",
       "      <td>0.047105</td>\n",
       "      <td>818.75460</td>\n",
       "      <td>795.78754</td>\n",
       "      <td>809.48720</td>\n",
       "      <td>808.27840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.432752</th>\n",
       "      <td>0.692926</td>\n",
       "      <td>0.708925</td>\n",
       "      <td>0.351733</td>\n",
       "      <td>0.946131</td>\n",
       "      <td>0.495369</td>\n",
       "      <td>0.739958</td>\n",
       "      <td>0.411359</td>\n",
       "      <td>0.828658</td>\n",
       "      <td>0.805521</td>\n",
       "      <td>0.891976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655304</td>\n",
       "      <td>1.040896</td>\n",
       "      <td>0.488659</td>\n",
       "      <td>0.405288</td>\n",
       "      <td>0.503926</td>\n",
       "      <td>1.185380</td>\n",
       "      <td>769.59705</td>\n",
       "      <td>804.65204</td>\n",
       "      <td>799.01100</td>\n",
       "      <td>761.94140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.718750</th>\n",
       "      <td>0.558745</td>\n",
       "      <td>0.527176</td>\n",
       "      <td>0.657075</td>\n",
       "      <td>0.348314</td>\n",
       "      <td>0.365544</td>\n",
       "      <td>0.420508</td>\n",
       "      <td>0.662045</td>\n",
       "      <td>0.804688</td>\n",
       "      <td>0.411531</td>\n",
       "      <td>0.520071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048361</td>\n",
       "      <td>0.397905</td>\n",
       "      <td>-0.008378</td>\n",
       "      <td>-0.060147</td>\n",
       "      <td>-0.102181</td>\n",
       "      <td>-0.022893</td>\n",
       "      <td>800.21980</td>\n",
       "      <td>840.91580</td>\n",
       "      <td>802.23444</td>\n",
       "      <td>794.57874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.487070</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.415245</td>\n",
       "      <td>0.435185</td>\n",
       "      <td>0.490844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.265079</td>\n",
       "      <td>0.475885</td>\n",
       "      <td>0.976564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.074563</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065228</td>\n",
       "      <td>0.586418</td>\n",
       "      <td>0.292501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.499837</td>\n",
       "      <td>0.222037</td>\n",
       "      <td>756.30035</td>\n",
       "      <td>936.81320</td>\n",
       "      <td>805.86080</td>\n",
       "      <td>743.80950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.056968</th>\n",
       "      <td>0.211855</td>\n",
       "      <td>0.974965</td>\n",
       "      <td>0.291571</td>\n",
       "      <td>0.473342</td>\n",
       "      <td>0.379526</td>\n",
       "      <td>1.013598</td>\n",
       "      <td>0.600822</td>\n",
       "      <td>0.528729</td>\n",
       "      <td>0.553123</td>\n",
       "      <td>1.214852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>0.975156</td>\n",
       "      <td>0.650653</td>\n",
       "      <td>0.488998</td>\n",
       "      <td>0.154784</td>\n",
       "      <td>0.828874</td>\n",
       "      <td>801.02563</td>\n",
       "      <td>786.11720</td>\n",
       "      <td>790.54944</td>\n",
       "      <td>810.69600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.357012</th>\n",
       "      <td>0.014308</td>\n",
       "      <td>0.472337</td>\n",
       "      <td>0.535962</td>\n",
       "      <td>-0.004001</td>\n",
       "      <td>-0.215976</td>\n",
       "      <td>0.101194</td>\n",
       "      <td>0.195486</td>\n",
       "      <td>0.245991</td>\n",
       "      <td>0.284263</td>\n",
       "      <td>0.357514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172400</td>\n",
       "      <td>0.632563</td>\n",
       "      <td>0.264747</td>\n",
       "      <td>-0.074426</td>\n",
       "      <td>-0.319983</td>\n",
       "      <td>0.058731</td>\n",
       "      <td>784.10254</td>\n",
       "      <td>790.14655</td>\n",
       "      <td>804.65204</td>\n",
       "      <td>792.56410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.487026</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.276477</td>\n",
       "      <td>0.488548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183506</td>\n",
       "      <td>0.791690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.574950</td>\n",
       "      <td>0.247701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261872</td>\n",
       "      <td>795.78754</td>\n",
       "      <td>1018.60803</td>\n",
       "      <td>1015.78754</td>\n",
       "      <td>807.87550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.663098</th>\n",
       "      <td>0.730942</td>\n",
       "      <td>0.313637</td>\n",
       "      <td>0.482088</td>\n",
       "      <td>0.311050</td>\n",
       "      <td>0.777058</td>\n",
       "      <td>0.175257</td>\n",
       "      <td>0.658292</td>\n",
       "      <td>0.827657</td>\n",
       "      <td>0.693830</td>\n",
       "      <td>0.195481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299796</td>\n",
       "      <td>0.528057</td>\n",
       "      <td>0.419827</td>\n",
       "      <td>-0.009557</td>\n",
       "      <td>0.083650</td>\n",
       "      <td>0.441265</td>\n",
       "      <td>781.28204</td>\n",
       "      <td>795.38464</td>\n",
       "      <td>796.99634</td>\n",
       "      <td>796.19050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.526629</th>\n",
       "      <td>1.005615</td>\n",
       "      <td>0.954518</td>\n",
       "      <td>0.333834</td>\n",
       "      <td>0.497046</td>\n",
       "      <td>-0.224240</td>\n",
       "      <td>0.912116</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.568480</td>\n",
       "      <td>0.057895</td>\n",
       "      <td>0.784356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192154</td>\n",
       "      <td>0.259321</td>\n",
       "      <td>0.078668</td>\n",
       "      <td>-0.781721</td>\n",
       "      <td>-0.118701</td>\n",
       "      <td>0.073226</td>\n",
       "      <td>805.86080</td>\n",
       "      <td>908.20514</td>\n",
       "      <td>799.41394</td>\n",
       "      <td>822.78390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.531769</th>\n",
       "      <td>1.041777</td>\n",
       "      <td>0.788743</td>\n",
       "      <td>-0.456831</td>\n",
       "      <td>0.814564</td>\n",
       "      <td>0.647147</td>\n",
       "      <td>0.559334</td>\n",
       "      <td>0.453286</td>\n",
       "      <td>0.866814</td>\n",
       "      <td>0.601203</td>\n",
       "      <td>0.316019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195708</td>\n",
       "      <td>1.000487</td>\n",
       "      <td>1.514561</td>\n",
       "      <td>-0.355864</td>\n",
       "      <td>0.054773</td>\n",
       "      <td>1.180761</td>\n",
       "      <td>830.43960</td>\n",
       "      <td>805.86080</td>\n",
       "      <td>782.49084</td>\n",
       "      <td>788.53480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.225120</th>\n",
       "      <td>-0.147522</td>\n",
       "      <td>1.095568</td>\n",
       "      <td>0.788109</td>\n",
       "      <td>0.535690</td>\n",
       "      <td>-0.093300</td>\n",
       "      <td>1.034610</td>\n",
       "      <td>0.669735</td>\n",
       "      <td>0.990046</td>\n",
       "      <td>0.214001</td>\n",
       "      <td>0.875288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293054</td>\n",
       "      <td>0.898597</td>\n",
       "      <td>0.436874</td>\n",
       "      <td>0.643182</td>\n",
       "      <td>-0.230484</td>\n",
       "      <td>0.776700</td>\n",
       "      <td>803.04030</td>\n",
       "      <td>803.44324</td>\n",
       "      <td>802.63740</td>\n",
       "      <td>819.15753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.481116</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292700</td>\n",
       "      <td>0.541598</td>\n",
       "      <td>0.781289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444640</td>\n",
       "      <td>0.567644</td>\n",
       "      <td>0.624123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.387306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191733</td>\n",
       "      <td>0.321507</td>\n",
       "      <td>0.762541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.169691</td>\n",
       "      <td>0.261460</td>\n",
       "      <td>444.83517</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>849.78020</td>\n",
       "      <td>514.13920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.230538</th>\n",
       "      <td>0.752996</td>\n",
       "      <td>0.901540</td>\n",
       "      <td>0.114042</td>\n",
       "      <td>0.143258</td>\n",
       "      <td>0.383760</td>\n",
       "      <td>0.771814</td>\n",
       "      <td>0.131482</td>\n",
       "      <td>0.482298</td>\n",
       "      <td>0.536388</td>\n",
       "      <td>0.744347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156814</td>\n",
       "      <td>0.185001</td>\n",
       "      <td>0.120361</td>\n",
       "      <td>-0.413380</td>\n",
       "      <td>-0.331284</td>\n",
       "      <td>0.073858</td>\n",
       "      <td>811.09890</td>\n",
       "      <td>808.27840</td>\n",
       "      <td>777.65570</td>\n",
       "      <td>790.14655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.389395</th>\n",
       "      <td>0.081237</td>\n",
       "      <td>-0.107577</td>\n",
       "      <td>0.177658</td>\n",
       "      <td>-0.070793</td>\n",
       "      <td>-0.144909</td>\n",
       "      <td>-0.056328</td>\n",
       "      <td>0.166743</td>\n",
       "      <td>0.579854</td>\n",
       "      <td>0.298377</td>\n",
       "      <td>0.123030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242487</td>\n",
       "      <td>0.651823</td>\n",
       "      <td>0.411299</td>\n",
       "      <td>-0.171896</td>\n",
       "      <td>0.148351</td>\n",
       "      <td>0.290528</td>\n",
       "      <td>788.13190</td>\n",
       "      <td>788.93774</td>\n",
       "      <td>791.75824</td>\n",
       "      <td>802.63740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-3.568150</th>\n",
       "      <td>1.542269</td>\n",
       "      <td>1.082342</td>\n",
       "      <td>-3.088205</td>\n",
       "      <td>-3.589948</td>\n",
       "      <td>1.197524</td>\n",
       "      <td>0.739411</td>\n",
       "      <td>-3.072707</td>\n",
       "      <td>-3.197447</td>\n",
       "      <td>0.352736</td>\n",
       "      <td>0.487300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730621</td>\n",
       "      <td>-2.936960</td>\n",
       "      <td>-2.995833</td>\n",
       "      <td>0.260758</td>\n",
       "      <td>0.322511</td>\n",
       "      <td>-3.177581</td>\n",
       "      <td>1606.48350</td>\n",
       "      <td>790.54944</td>\n",
       "      <td>714.79850</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.081728</th>\n",
       "      <td>0.200165</td>\n",
       "      <td>0.474451</td>\n",
       "      <td>-0.115841</td>\n",
       "      <td>0.035747</td>\n",
       "      <td>-0.145280</td>\n",
       "      <td>0.045874</td>\n",
       "      <td>0.165665</td>\n",
       "      <td>0.748375</td>\n",
       "      <td>0.099980</td>\n",
       "      <td>0.100615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438258</td>\n",
       "      <td>0.431461</td>\n",
       "      <td>0.555326</td>\n",
       "      <td>-0.184453</td>\n",
       "      <td>0.197267</td>\n",
       "      <td>0.499843</td>\n",
       "      <td>800.62270</td>\n",
       "      <td>781.28204</td>\n",
       "      <td>801.83150</td>\n",
       "      <td>777.65570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.111698</th>\n",
       "      <td>0.932106</td>\n",
       "      <td>1.092467</td>\n",
       "      <td>0.151687</td>\n",
       "      <td>0.148265</td>\n",
       "      <td>0.618712</td>\n",
       "      <td>0.506503</td>\n",
       "      <td>0.528306</td>\n",
       "      <td>0.360360</td>\n",
       "      <td>0.398001</td>\n",
       "      <td>0.605844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587615</td>\n",
       "      <td>0.930837</td>\n",
       "      <td>0.287210</td>\n",
       "      <td>0.417403</td>\n",
       "      <td>0.528995</td>\n",
       "      <td>0.963639</td>\n",
       "      <td>766.37360</td>\n",
       "      <td>809.48720</td>\n",
       "      <td>791.75824</td>\n",
       "      <td>776.44690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.878025</th>\n",
       "      <td>0.084981</td>\n",
       "      <td>-0.266131</td>\n",
       "      <td>0.879492</td>\n",
       "      <td>0.799393</td>\n",
       "      <td>-0.156243</td>\n",
       "      <td>-0.324086</td>\n",
       "      <td>0.713840</td>\n",
       "      <td>1.243598</td>\n",
       "      <td>0.678876</td>\n",
       "      <td>0.050704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307649</td>\n",
       "      <td>0.700844</td>\n",
       "      <td>0.310464</td>\n",
       "      <td>0.549019</td>\n",
       "      <td>0.104566</td>\n",
       "      <td>0.291018</td>\n",
       "      <td>792.56410</td>\n",
       "      <td>815.93410</td>\n",
       "      <td>799.81683</td>\n",
       "      <td>792.16120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.921296</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.001759</td>\n",
       "      <td>0.905998</td>\n",
       "      <td>0.597991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430171</td>\n",
       "      <td>0.578002</td>\n",
       "      <td>1.216512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073163</td>\n",
       "      <td>0.616764</td>\n",
       "      <td>0.382557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.038395</td>\n",
       "      <td>0.304299</td>\n",
       "      <td>929.96340</td>\n",
       "      <td>1330.07320</td>\n",
       "      <td>661.61170</td>\n",
       "      <td>943.26010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.877619</th>\n",
       "      <td>-0.048339</td>\n",
       "      <td>0.664786</td>\n",
       "      <td>1.217797</td>\n",
       "      <td>0.400997</td>\n",
       "      <td>-0.137241</td>\n",
       "      <td>0.360346</td>\n",
       "      <td>0.917463</td>\n",
       "      <td>0.449785</td>\n",
       "      <td>-0.121847</td>\n",
       "      <td>0.463507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181647</td>\n",
       "      <td>1.130002</td>\n",
       "      <td>0.141631</td>\n",
       "      <td>-0.130767</td>\n",
       "      <td>-0.253356</td>\n",
       "      <td>0.334861</td>\n",
       "      <td>809.89014</td>\n",
       "      <td>798.20514</td>\n",
       "      <td>810.29300</td>\n",
       "      <td>783.29670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.404254</th>\n",
       "      <td>1.010500</td>\n",
       "      <td>0.625734</td>\n",
       "      <td>0.318266</td>\n",
       "      <td>0.673591</td>\n",
       "      <td>1.115781</td>\n",
       "      <td>0.425740</td>\n",
       "      <td>0.512786</td>\n",
       "      <td>0.718054</td>\n",
       "      <td>0.389925</td>\n",
       "      <td>0.475921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.817259</td>\n",
       "      <td>0.784826</td>\n",
       "      <td>0.184192</td>\n",
       "      <td>0.975612</td>\n",
       "      <td>0.350049</td>\n",
       "      <td>0.567323</td>\n",
       "      <td>740.98900</td>\n",
       "      <td>884.02930</td>\n",
       "      <td>797.80220</td>\n",
       "      <td>722.45420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.048582</th>\n",
       "      <td>1.146473</td>\n",
       "      <td>0.368723</td>\n",
       "      <td>0.447418</td>\n",
       "      <td>0.764993</td>\n",
       "      <td>1.110223</td>\n",
       "      <td>0.309190</td>\n",
       "      <td>0.732800</td>\n",
       "      <td>0.840009</td>\n",
       "      <td>0.903866</td>\n",
       "      <td>0.272798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422641</td>\n",
       "      <td>0.943477</td>\n",
       "      <td>0.066368</td>\n",
       "      <td>0.645398</td>\n",
       "      <td>0.443999</td>\n",
       "      <td>0.330189</td>\n",
       "      <td>832.45420</td>\n",
       "      <td>785.31134</td>\n",
       "      <td>787.32600</td>\n",
       "      <td>839.30400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.050515</th>\n",
       "      <td>0.170735</td>\n",
       "      <td>0.207602</td>\n",
       "      <td>0.936386</td>\n",
       "      <td>0.832309</td>\n",
       "      <td>-0.207354</td>\n",
       "      <td>-0.233017</td>\n",
       "      <td>0.500650</td>\n",
       "      <td>0.968307</td>\n",
       "      <td>0.105750</td>\n",
       "      <td>0.190839</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171633</td>\n",
       "      <td>0.589225</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>-0.480640</td>\n",
       "      <td>-0.698967</td>\n",
       "      <td>0.308598</td>\n",
       "      <td>782.89380</td>\n",
       "      <td>798.20514</td>\n",
       "      <td>804.65204</td>\n",
       "      <td>808.27840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.818705</th>\n",
       "      <td>0.522876</td>\n",
       "      <td>0.487333</td>\n",
       "      <td>0.797058</td>\n",
       "      <td>0.728746</td>\n",
       "      <td>0.175932</td>\n",
       "      <td>-0.109918</td>\n",
       "      <td>0.767915</td>\n",
       "      <td>1.160006</td>\n",
       "      <td>0.332457</td>\n",
       "      <td>0.357286</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061573</td>\n",
       "      <td>0.943796</td>\n",
       "      <td>1.279114</td>\n",
       "      <td>-0.481174</td>\n",
       "      <td>-0.478908</td>\n",
       "      <td>0.969057</td>\n",
       "      <td>786.11720</td>\n",
       "      <td>788.13190</td>\n",
       "      <td>798.20514</td>\n",
       "      <td>789.74360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.733242</th>\n",
       "      <td>1.005615</td>\n",
       "      <td>0.175528</td>\n",
       "      <td>0.495598</td>\n",
       "      <td>0.797691</td>\n",
       "      <td>-0.224240</td>\n",
       "      <td>-0.003238</td>\n",
       "      <td>0.301580</td>\n",
       "      <td>1.215429</td>\n",
       "      <td>0.057895</td>\n",
       "      <td>0.291347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013340</td>\n",
       "      <td>0.331940</td>\n",
       "      <td>0.383989</td>\n",
       "      <td>-0.781721</td>\n",
       "      <td>-0.140249</td>\n",
       "      <td>0.030793</td>\n",
       "      <td>794.57874</td>\n",
       "      <td>750.25640</td>\n",
       "      <td>840.51280</td>\n",
       "      <td>803.84610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-3.568150</th>\n",
       "      <td>0.575764</td>\n",
       "      <td>0.195717</td>\n",
       "      <td>-3.088205</td>\n",
       "      <td>-3.589948</td>\n",
       "      <td>0.213201</td>\n",
       "      <td>0.166979</td>\n",
       "      <td>-3.072707</td>\n",
       "      <td>-3.197447</td>\n",
       "      <td>0.489531</td>\n",
       "      <td>0.307746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715230</td>\n",
       "      <td>-2.936960</td>\n",
       "      <td>-2.995833</td>\n",
       "      <td>0.505250</td>\n",
       "      <td>0.550919</td>\n",
       "      <td>-3.177581</td>\n",
       "      <td>1430.00000</td>\n",
       "      <td>784.90845</td>\n",
       "      <td>786.11720</td>\n",
       "      <td>1283.73620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.543511</th>\n",
       "      <td>0.761250</td>\n",
       "      <td>0.892835</td>\n",
       "      <td>0.198413</td>\n",
       "      <td>0.482428</td>\n",
       "      <td>0.499936</td>\n",
       "      <td>0.400965</td>\n",
       "      <td>0.482605</td>\n",
       "      <td>0.869670</td>\n",
       "      <td>0.673918</td>\n",
       "      <td>0.312851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494830</td>\n",
       "      <td>0.630488</td>\n",
       "      <td>0.366140</td>\n",
       "      <td>-0.187385</td>\n",
       "      <td>0.166574</td>\n",
       "      <td>0.355711</td>\n",
       "      <td>819.56040</td>\n",
       "      <td>794.17584</td>\n",
       "      <td>800.21980</td>\n",
       "      <td>824.39560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.578504</th>\n",
       "      <td>0.623496</td>\n",
       "      <td>0.999317</td>\n",
       "      <td>0.085384</td>\n",
       "      <td>0.496571</td>\n",
       "      <td>0.386965</td>\n",
       "      <td>0.408251</td>\n",
       "      <td>0.401628</td>\n",
       "      <td>0.723497</td>\n",
       "      <td>0.531996</td>\n",
       "      <td>0.235414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125749</td>\n",
       "      <td>1.019573</td>\n",
       "      <td>0.904326</td>\n",
       "      <td>-0.124254</td>\n",
       "      <td>-0.167107</td>\n",
       "      <td>0.622729</td>\n",
       "      <td>808.68134</td>\n",
       "      <td>804.24910</td>\n",
       "      <td>791.35530</td>\n",
       "      <td>803.04030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.140964</th>\n",
       "      <td>1.001210</td>\n",
       "      <td>0.433489</td>\n",
       "      <td>0.612387</td>\n",
       "      <td>0.942202</td>\n",
       "      <td>0.910873</td>\n",
       "      <td>0.287559</td>\n",
       "      <td>0.190156</td>\n",
       "      <td>1.138860</td>\n",
       "      <td>0.703240</td>\n",
       "      <td>0.115628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214793</td>\n",
       "      <td>0.891544</td>\n",
       "      <td>0.646883</td>\n",
       "      <td>0.564142</td>\n",
       "      <td>0.050763</td>\n",
       "      <td>0.479454</td>\n",
       "      <td>586.66670</td>\n",
       "      <td>795.38464</td>\n",
       "      <td>821.57510</td>\n",
       "      <td>799.41394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.501428</th>\n",
       "      <td>0.947632</td>\n",
       "      <td>0.101118</td>\n",
       "      <td>0.585716</td>\n",
       "      <td>0.372999</td>\n",
       "      <td>0.705303</td>\n",
       "      <td>-0.111012</td>\n",
       "      <td>0.485338</td>\n",
       "      <td>0.664019</td>\n",
       "      <td>0.549264</td>\n",
       "      <td>0.263357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082955</td>\n",
       "      <td>0.648795</td>\n",
       "      <td>0.508110</td>\n",
       "      <td>0.929696</td>\n",
       "      <td>-0.482927</td>\n",
       "      <td>0.270117</td>\n",
       "      <td>794.57874</td>\n",
       "      <td>1082.27110</td>\n",
       "      <td>796.19050</td>\n",
       "      <td>802.23444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.826584</th>\n",
       "      <td>-0.140653</td>\n",
       "      <td>0.632153</td>\n",
       "      <td>1.083599</td>\n",
       "      <td>0.472049</td>\n",
       "      <td>-0.222746</td>\n",
       "      <td>0.276511</td>\n",
       "      <td>0.765145</td>\n",
       "      <td>0.828804</td>\n",
       "      <td>0.228187</td>\n",
       "      <td>0.735413</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060209</td>\n",
       "      <td>0.581531</td>\n",
       "      <td>0.199958</td>\n",
       "      <td>0.878257</td>\n",
       "      <td>-0.321140</td>\n",
       "      <td>0.472405</td>\n",
       "      <td>803.04030</td>\n",
       "      <td>811.50183</td>\n",
       "      <td>795.38464</td>\n",
       "      <td>809.08420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.283943</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.992947</td>\n",
       "      <td>0.056337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.822342</td>\n",
       "      <td>0.228753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.716345</td>\n",
       "      <td>0.012694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.339731</td>\n",
       "      <td>791.75824</td>\n",
       "      <td>1163.26010</td>\n",
       "      <td>1006.52014</td>\n",
       "      <td>794.57874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.137270</th>\n",
       "      <td>1.354733</td>\n",
       "      <td>1.390062</td>\n",
       "      <td>0.007934</td>\n",
       "      <td>0.354955</td>\n",
       "      <td>1.110592</td>\n",
       "      <td>0.940581</td>\n",
       "      <td>0.220950</td>\n",
       "      <td>0.584299</td>\n",
       "      <td>0.597875</td>\n",
       "      <td>0.822651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204154</td>\n",
       "      <td>0.885163</td>\n",
       "      <td>0.342910</td>\n",
       "      <td>-0.075824</td>\n",
       "      <td>-0.006954</td>\n",
       "      <td>0.386288</td>\n",
       "      <td>724.06590</td>\n",
       "      <td>738.97437</td>\n",
       "      <td>847.76556</td>\n",
       "      <td>776.04395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.480742</th>\n",
       "      <td>0.422477</td>\n",
       "      <td>0.222408</td>\n",
       "      <td>0.593219</td>\n",
       "      <td>0.198445</td>\n",
       "      <td>0.399677</td>\n",
       "      <td>0.261644</td>\n",
       "      <td>0.202707</td>\n",
       "      <td>0.669944</td>\n",
       "      <td>0.770185</td>\n",
       "      <td>0.353980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795542</td>\n",
       "      <td>0.694956</td>\n",
       "      <td>0.446513</td>\n",
       "      <td>0.810262</td>\n",
       "      <td>0.425074</td>\n",
       "      <td>0.499693</td>\n",
       "      <td>869.92676</td>\n",
       "      <td>824.79850</td>\n",
       "      <td>823.99270</td>\n",
       "      <td>882.41760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.834978</th>\n",
       "      <td>0.947632</td>\n",
       "      <td>0.239633</td>\n",
       "      <td>0.943042</td>\n",
       "      <td>0.866654</td>\n",
       "      <td>0.705303</td>\n",
       "      <td>0.040801</td>\n",
       "      <td>0.810647</td>\n",
       "      <td>1.048910</td>\n",
       "      <td>0.549264</td>\n",
       "      <td>0.253019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027225</td>\n",
       "      <td>0.572320</td>\n",
       "      <td>0.949144</td>\n",
       "      <td>0.929696</td>\n",
       "      <td>-0.341732</td>\n",
       "      <td>0.004771</td>\n",
       "      <td>758.71796</td>\n",
       "      <td>751.86810</td>\n",
       "      <td>816.33700</td>\n",
       "      <td>762.74725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.032912</th>\n",
       "      <td>0.947632</td>\n",
       "      <td>0.353598</td>\n",
       "      <td>0.272894</td>\n",
       "      <td>0.045426</td>\n",
       "      <td>0.705303</td>\n",
       "      <td>-0.232622</td>\n",
       "      <td>0.335352</td>\n",
       "      <td>0.600159</td>\n",
       "      <td>0.549264</td>\n",
       "      <td>0.281622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012751</td>\n",
       "      <td>0.860762</td>\n",
       "      <td>0.962885</td>\n",
       "      <td>0.929696</td>\n",
       "      <td>-0.075575</td>\n",
       "      <td>0.736831</td>\n",
       "      <td>823.99270</td>\n",
       "      <td>860.65936</td>\n",
       "      <td>804.24910</td>\n",
       "      <td>821.57510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.416303</th>\n",
       "      <td>0.261179</td>\n",
       "      <td>0.494191</td>\n",
       "      <td>0.451763</td>\n",
       "      <td>0.501586</td>\n",
       "      <td>-0.184935</td>\n",
       "      <td>-0.245841</td>\n",
       "      <td>0.086255</td>\n",
       "      <td>0.347624</td>\n",
       "      <td>-0.195297</td>\n",
       "      <td>0.164723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411057</td>\n",
       "      <td>0.552298</td>\n",
       "      <td>0.536953</td>\n",
       "      <td>-0.052702</td>\n",
       "      <td>0.323461</td>\n",
       "      <td>0.354430</td>\n",
       "      <td>799.81683</td>\n",
       "      <td>798.20514</td>\n",
       "      <td>790.54944</td>\n",
       "      <td>784.90845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.737815</th>\n",
       "      <td>0.947632</td>\n",
       "      <td>0.486358</td>\n",
       "      <td>0.988660</td>\n",
       "      <td>0.619816</td>\n",
       "      <td>0.705303</td>\n",
       "      <td>0.037808</td>\n",
       "      <td>0.766195</td>\n",
       "      <td>0.789052</td>\n",
       "      <td>0.549264</td>\n",
       "      <td>0.293965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141221</td>\n",
       "      <td>0.778927</td>\n",
       "      <td>0.346570</td>\n",
       "      <td>0.929696</td>\n",
       "      <td>-0.399023</td>\n",
       "      <td>0.461160</td>\n",
       "      <td>798.60803</td>\n",
       "      <td>921.50183</td>\n",
       "      <td>800.21980</td>\n",
       "      <td>807.87550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.085366</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292700</td>\n",
       "      <td>-0.101065</td>\n",
       "      <td>0.769120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444640</td>\n",
       "      <td>0.472890</td>\n",
       "      <td>0.831946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.387306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191733</td>\n",
       "      <td>0.438477</td>\n",
       "      <td>0.785193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.169691</td>\n",
       "      <td>0.375424</td>\n",
       "      <td>783.29670</td>\n",
       "      <td>996.04395</td>\n",
       "      <td>956.55676</td>\n",
       "      <td>800.21980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.257929</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.192638</td>\n",
       "      <td>0.274711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.187285</td>\n",
       "      <td>0.708340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.574186</td>\n",
       "      <td>0.056651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.374387</td>\n",
       "      <td>790.54944</td>\n",
       "      <td>1098.38830</td>\n",
       "      <td>1058.09520</td>\n",
       "      <td>787.32600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.451732</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533058</td>\n",
       "      <td>0.332098</td>\n",
       "      <td>0.328802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.065744</td>\n",
       "      <td>0.285941</td>\n",
       "      <td>0.633542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385860</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032685</td>\n",
       "      <td>0.634369</td>\n",
       "      <td>0.857738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031477</td>\n",
       "      <td>0.196273</td>\n",
       "      <td>902.96704</td>\n",
       "      <td>1257.14280</td>\n",
       "      <td>792.96704</td>\n",
       "      <td>814.32230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.553063</th>\n",
       "      <td>0.061859</td>\n",
       "      <td>0.625655</td>\n",
       "      <td>1.150994</td>\n",
       "      <td>0.674445</td>\n",
       "      <td>-0.507383</td>\n",
       "      <td>-0.068278</td>\n",
       "      <td>0.628535</td>\n",
       "      <td>0.859918</td>\n",
       "      <td>-0.161795</td>\n",
       "      <td>0.025912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586939</td>\n",
       "      <td>0.586484</td>\n",
       "      <td>0.349433</td>\n",
       "      <td>0.099045</td>\n",
       "      <td>0.164682</td>\n",
       "      <td>0.241952</td>\n",
       "      <td>803.44324</td>\n",
       "      <td>801.83150</td>\n",
       "      <td>772.82050</td>\n",
       "      <td>808.27840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.094362</th>\n",
       "      <td>0.253535</td>\n",
       "      <td>0.578154</td>\n",
       "      <td>-0.062220</td>\n",
       "      <td>0.294632</td>\n",
       "      <td>0.212852</td>\n",
       "      <td>-0.064238</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.600322</td>\n",
       "      <td>-0.130791</td>\n",
       "      <td>0.468704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875127</td>\n",
       "      <td>0.352823</td>\n",
       "      <td>0.206953</td>\n",
       "      <td>-0.554928</td>\n",
       "      <td>0.434432</td>\n",
       "      <td>0.242781</td>\n",
       "      <td>807.47253</td>\n",
       "      <td>667.65570</td>\n",
       "      <td>743.40660</td>\n",
       "      <td>801.42860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.432693</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.240930</td>\n",
       "      <td>0.726266</td>\n",
       "      <td>0.581308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.153397</td>\n",
       "      <td>0.853867</td>\n",
       "      <td>0.777959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317499</td>\n",
       "      <td>0.582944</td>\n",
       "      <td>0.744184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.180695</td>\n",
       "      <td>0.487011</td>\n",
       "      <td>643.88280</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>801.02563</td>\n",
       "      <td>484.32236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.446872</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356500</td>\n",
       "      <td>0.393457</td>\n",
       "      <td>0.235539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167864</td>\n",
       "      <td>0.073203</td>\n",
       "      <td>0.787091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065892</td>\n",
       "      <td>0.427456</td>\n",
       "      <td>0.198055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.269374</td>\n",
       "      <td>-0.006804</td>\n",
       "      <td>765.97070</td>\n",
       "      <td>639.85345</td>\n",
       "      <td>797.80220</td>\n",
       "      <td>760.73260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-3.198223</th>\n",
       "      <td>1.102126</td>\n",
       "      <td>0.734470</td>\n",
       "      <td>0.117763</td>\n",
       "      <td>-3.141619</td>\n",
       "      <td>0.579252</td>\n",
       "      <td>0.406657</td>\n",
       "      <td>0.026801</td>\n",
       "      <td>-2.738614</td>\n",
       "      <td>0.789397</td>\n",
       "      <td>0.519235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438625</td>\n",
       "      <td>0.528602</td>\n",
       "      <td>-2.644557</td>\n",
       "      <td>-0.203229</td>\n",
       "      <td>0.033799</td>\n",
       "      <td>0.259945</td>\n",
       "      <td>678.13190</td>\n",
       "      <td>850.98900</td>\n",
       "      <td>718.82780</td>\n",
       "      <td>696.26373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.580014</th>\n",
       "      <td>0.215211</td>\n",
       "      <td>0.175429</td>\n",
       "      <td>0.476784</td>\n",
       "      <td>0.722963</td>\n",
       "      <td>-0.101904</td>\n",
       "      <td>-0.147266</td>\n",
       "      <td>0.564787</td>\n",
       "      <td>0.920594</td>\n",
       "      <td>0.279353</td>\n",
       "      <td>0.131609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118514</td>\n",
       "      <td>0.592762</td>\n",
       "      <td>0.265791</td>\n",
       "      <td>-0.442767</td>\n",
       "      <td>-0.269060</td>\n",
       "      <td>0.281754</td>\n",
       "      <td>823.58970</td>\n",
       "      <td>808.68134</td>\n",
       "      <td>799.81683</td>\n",
       "      <td>832.05130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11540 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Delta_AF7  Delta_AF8  Delta_TP10  Theta_TP9  Theta_AF7  Theta_AF8  \\\n",
       "Delta_TP9                                                                      \n",
       " 0.540034   0.803615  -0.263441    0.168931   0.159531   0.356520  -0.295784   \n",
       " 0.149771   0.253535   0.578154    0.606145   0.009796   0.212852  -0.064238   \n",
       "-0.066366  -0.453483  -0.069380    0.105457  -0.193809  -0.402539   0.003401   \n",
       " 0.218026   0.000000   0.467383    0.888921   0.095387   0.000000   0.089932   \n",
       " 0.971143   0.613813   0.366377    0.991649   0.733046  -0.047291   0.050081   \n",
       " 0.676671   0.680080   0.656523    0.803457   0.182391  -0.124810   0.418654   \n",
       " 0.213173   0.000000   0.292700    0.282793   0.711423   0.000000   0.444640   \n",
       " 0.323069   0.215630   0.675818    0.699674   0.151315  -0.718794   0.402615   \n",
       " 0.963676  -0.584777   0.221903    0.302150   0.558278  -0.763722   0.182198   \n",
       " 1.318964   0.022107   0.446671    1.532767   1.606674   0.176633   0.029063   \n",
       "-3.198223   0.585866   0.147618    1.055047  -3.141619   0.388110  -0.180329   \n",
       " 0.365441   0.000000   1.001759    0.212007   0.697192   0.000000   0.430171   \n",
       " 0.918767   0.448193   0.419216    0.984369   0.175284   0.548527   0.307808   \n",
       " 0.411681   0.196430   0.416002    0.583321   0.300464  -0.072520  -0.393444   \n",
       " 1.432752   0.692926   0.708925    0.351733   0.946131   0.495369   0.739958   \n",
       " 0.718750   0.558745   0.527176    0.657075   0.348314   0.365544   0.420508   \n",
       " 0.487070   0.000000  -0.415245    0.435185   0.490844   0.000000  -0.265079   \n",
       " 0.056968   0.211855   0.974965    0.291571   0.473342   0.379526   1.013598   \n",
       " 0.357012   0.014308   0.472337    0.535962  -0.004001  -0.215976   0.101194   \n",
       " 0.487026   0.000000   0.000000    0.276477   0.488548   0.000000   0.000000   \n",
       " 0.663098   0.730942   0.313637    0.482088   0.311050   0.777058   0.175257   \n",
       " 0.526629   1.005615   0.954518    0.333834   0.497046  -0.224240   0.912116   \n",
       " 0.531769   1.041777   0.788743   -0.456831   0.814564   0.647147   0.559334   \n",
       " 0.225120  -0.147522   1.095568    0.788109   0.535690  -0.093300   1.034610   \n",
       " 0.481116   0.000000   0.292700    0.541598   0.781289   0.000000   0.444640   \n",
       " 0.230538   0.752996   0.901540    0.114042   0.143258   0.383760   0.771814   \n",
       " 0.389395   0.081237  -0.107577    0.177658  -0.070793  -0.144909  -0.056328   \n",
       "-3.568150   1.542269   1.082342   -3.088205  -3.589948   1.197524   0.739411   \n",
       " 0.081728   0.200165   0.474451   -0.115841   0.035747  -0.145280   0.045874   \n",
       " 0.111698   0.932106   1.092467    0.151687   0.148265   0.618712   0.506503   \n",
       "...              ...        ...         ...        ...        ...        ...   \n",
       " 0.878025   0.084981  -0.266131    0.879492   0.799393  -0.156243  -0.324086   \n",
       " 0.921296   0.000000   1.001759    0.905998   0.597991   0.000000   0.430171   \n",
       " 0.877619  -0.048339   0.664786    1.217797   0.400997  -0.137241   0.360346   \n",
       "-0.404254   1.010500   0.625734    0.318266   0.673591   1.115781   0.425740   \n",
       " 0.048582   1.146473   0.368723    0.447418   0.764993   1.110223   0.309190   \n",
       " 1.050515   0.170735   0.207602    0.936386   0.832309  -0.207354  -0.233017   \n",
       " 0.818705   0.522876   0.487333    0.797058   0.728746   0.175932  -0.109918   \n",
       " 0.733242   1.005615   0.175528    0.495598   0.797691  -0.224240  -0.003238   \n",
       "-3.568150   0.575764   0.195717   -3.088205  -3.589948   0.213201   0.166979   \n",
       " 0.543511   0.761250   0.892835    0.198413   0.482428   0.499936   0.400965   \n",
       " 0.578504   0.623496   0.999317    0.085384   0.496571   0.386965   0.408251   \n",
       " 1.140964   1.001210   0.433489    0.612387   0.942202   0.910873   0.287559   \n",
       " 0.501428   0.947632   0.101118    0.585716   0.372999   0.705303  -0.111012   \n",
       " 0.826584  -0.140653   0.632153    1.083599   0.472049  -0.222746   0.276511   \n",
       "-0.283943   0.000000   0.000000    0.992947   0.056337   0.000000   0.000000   \n",
       " 0.137270   1.354733   1.390062    0.007934   0.354955   1.110592   0.940581   \n",
       " 0.480742   0.422477   0.222408    0.593219   0.198445   0.399677   0.261644   \n",
       " 0.834978   0.947632   0.239633    0.943042   0.866654   0.705303   0.040801   \n",
       "-0.032912   0.947632   0.353598    0.272894   0.045426   0.705303  -0.232622   \n",
       " 0.416303   0.261179   0.494191    0.451763   0.501586  -0.184935  -0.245841   \n",
       " 0.737815   0.947632   0.486358    0.988660   0.619816   0.705303   0.037808   \n",
       "-0.085366   0.000000   0.292700   -0.101065   0.769120   0.000000   0.444640   \n",
       " 0.257929   0.000000   0.000000    0.192638   0.274711   0.000000   0.000000   \n",
       " 0.451732   0.000000   0.533058    0.332098   0.328802   0.000000  -0.065744   \n",
       " 0.553063   0.061859   0.625655    1.150994   0.674445  -0.507383  -0.068278   \n",
       "-0.094362   0.253535   0.578154   -0.062220   0.294632   0.212852  -0.064238   \n",
       " 0.432693   0.000000  -0.240930    0.726266   0.581308   0.000000  -0.153397   \n",
       " 0.446872   0.000000   0.356500    0.393457   0.235539   0.000000   0.167864   \n",
       "-3.198223   1.102126   0.734470    0.117763  -3.141619   0.579252   0.406657   \n",
       " 0.580014   0.215211   0.175429    0.476784   0.722963  -0.101904  -0.147266   \n",
       "\n",
       "           Theta_TP10  Alpha_TP9  Alpha_AF7  Alpha_AF8     ...      Beta_AF8  \\\n",
       "Delta_TP9                                                  ...                 \n",
       " 0.540034    0.210762   0.718441   0.107953   0.286740     ...      0.581179   \n",
       " 0.149771    0.429435   0.221751  -0.130791   0.468704     ...      0.875127   \n",
       "-0.066366    0.145561   0.822553   0.098947   0.281481     ...      0.609252   \n",
       " 0.218026    0.844171   0.311854   0.000000   0.322353     ...      0.872978   \n",
       " 0.971143    0.794498   1.200492   0.185769   0.173454     ...      0.771983   \n",
       " 0.676671    0.252183   0.710622  -0.028109   0.414571     ...     -0.006982   \n",
       " 0.213173    0.677217   0.842879   0.000000   0.387306     ...      0.191733   \n",
       " 0.323069    0.740568   0.592953   0.073890   0.507593     ...      0.062287   \n",
       " 0.963676    0.437109   0.668945  -0.325872   0.270021     ...      0.148604   \n",
       " 1.318964    1.523138   1.586775   0.407694   0.146612     ...      0.051140   \n",
       "-3.198223    0.887871  -2.738614   0.564657   0.076474     ...     -0.043047   \n",
       " 0.365441    0.567525   0.649526   0.000000  -0.005612     ...      0.073163   \n",
       " 0.918767    0.485305   0.721031   0.503068   0.950567     ...      0.572322   \n",
       " 0.411681    0.344040   0.848451  -0.073310   0.163474     ...     -0.010701   \n",
       " 1.432752    0.411359   0.828658   0.805521   0.891976     ...      0.655304   \n",
       " 0.718750    0.662045   0.804688   0.411531   0.520071     ...     -0.048361   \n",
       " 0.487070    0.475885   0.976564   0.000000  -0.074563     ...     -0.065228   \n",
       " 0.056968    0.600822   0.528729   0.553123   1.214852     ...      0.623708   \n",
       " 0.357012    0.195486   0.245991   0.284263   0.357514     ...      0.172400   \n",
       " 0.487026    0.183506   0.791690   0.000000   0.000000     ...      0.000000   \n",
       " 0.663098    0.658292   0.827657   0.693830   0.195481     ...      0.299796   \n",
       " 0.526629    0.679145   0.568480   0.057895   0.784356     ...      0.192154   \n",
       " 0.531769    0.453286   0.866814   0.601203   0.316019     ...      0.195708   \n",
       " 0.225120    0.669735   0.990046   0.214001   0.875288     ...      0.293054   \n",
       " 0.481116    0.567644   0.624123   0.000000   0.387306     ...      0.191733   \n",
       " 0.230538    0.131482   0.482298   0.536388   0.744347     ...      0.156814   \n",
       " 0.389395    0.166743   0.579854   0.298377   0.123030     ...      0.242487   \n",
       "-3.568150   -3.072707  -3.197447   0.352736   0.487300     ...      0.730621   \n",
       " 0.081728    0.165665   0.748375   0.099980   0.100615     ...      0.438258   \n",
       " 0.111698    0.528306   0.360360   0.398001   0.605844     ...      0.587615   \n",
       "...               ...        ...        ...        ...     ...           ...   \n",
       " 0.878025    0.713840   1.243598   0.678876   0.050704     ...      0.307649   \n",
       " 0.921296    0.578002   1.216512   0.000000  -0.005612     ...      0.073163   \n",
       " 0.877619    0.917463   0.449785  -0.121847   0.463507     ...      0.181647   \n",
       "-0.404254    0.512786   0.718054   0.389925   0.475921     ...      0.817259   \n",
       " 0.048582    0.732800   0.840009   0.903866   0.272798     ...      0.422641   \n",
       " 1.050515    0.500650   0.968307   0.105750   0.190839     ...     -0.171633   \n",
       " 0.818705    0.767915   1.160006   0.332457   0.357286     ...     -0.061573   \n",
       " 0.733242    0.301580   1.215429   0.057895   0.291347     ...      0.013340   \n",
       "-3.568150   -3.072707  -3.197447   0.489531   0.307746     ...      0.715230   \n",
       " 0.543511    0.482605   0.869670   0.673918   0.312851     ...      0.494830   \n",
       " 0.578504    0.401628   0.723497   0.531996   0.235414     ...      0.125749   \n",
       " 1.140964    0.190156   1.138860   0.703240   0.115628     ...      0.214793   \n",
       " 0.501428    0.485338   0.664019   0.549264   0.263357     ...      0.082955   \n",
       " 0.826584    0.765145   0.828804   0.228187   0.735413     ...     -0.060209   \n",
       "-0.283943    0.822342   0.228753   0.000000   0.000000     ...      0.000000   \n",
       " 0.137270    0.220950   0.584299   0.597875   0.822651     ...      0.204154   \n",
       " 0.480742    0.202707   0.669944   0.770185   0.353980     ...      0.795542   \n",
       " 0.834978    0.810647   1.048910   0.549264   0.253019     ...      0.027225   \n",
       "-0.032912    0.335352   0.600159   0.549264   0.281622     ...      0.012751   \n",
       " 0.416303    0.086255   0.347624  -0.195297   0.164723     ...      0.411057   \n",
       " 0.737815    0.766195   0.789052   0.549264   0.293965     ...      0.141221   \n",
       "-0.085366    0.472890   0.831946   0.000000   0.387306     ...      0.191733   \n",
       " 0.257929   -0.187285   0.708340   0.000000   0.000000     ...      0.000000   \n",
       " 0.451732    0.285941   0.633542   0.000000   0.385860     ...     -0.032685   \n",
       " 0.553063    0.628535   0.859918  -0.161795   0.025912     ...      0.586939   \n",
       "-0.094362    0.361407   0.600322  -0.130791   0.468704     ...      0.875127   \n",
       " 0.432693    0.853867   0.777959   0.000000   0.230602     ...      0.317499   \n",
       " 0.446872    0.073203   0.787091   0.000000   0.189976     ...      0.065892   \n",
       "-3.198223    0.026801  -2.738614   0.789397   0.519235     ...      0.438625   \n",
       " 0.580014    0.564787   0.920594   0.279353   0.131609     ...      0.118514   \n",
       "\n",
       "           Beta_TP10  Gamma_TP9  Gamma_AF7  Gamma_AF8  Gamma_TP10     RAW_TP9  \\\n",
       "Delta_TP9                                                                       \n",
       " 0.540034   0.902186   0.655396   0.249737   0.410515    0.371228   863.47986   \n",
       " 0.149771   0.597081   0.255251  -0.554928   0.434432    0.476996   807.87550   \n",
       "-0.066366   0.486049   0.224205   0.857623   0.603281    0.177965   823.18680   \n",
       " 0.218026   0.800579  -0.262106   0.000000   0.355486    0.454008   804.24910   \n",
       " 0.971143   0.819066   0.448506   0.063187   0.458826    1.002911   819.56040   \n",
       " 0.676671   0.514306   0.241685  -0.361572  -0.172194    0.374023   812.71063   \n",
       " 0.213173   0.528343   0.739228   0.000000  -0.169691    0.269688   763.15020   \n",
       " 0.323069   0.973163   0.803525   0.263728  -0.076880    0.821955   796.99634   \n",
       " 0.963676   0.274723   0.789660  -0.151043  -0.383720    0.133214   831.24540   \n",
       " 1.318964   0.845428   0.329852   1.003507   0.109267    0.162069   811.90480   \n",
       "-3.198223   0.489032  -2.644557  -0.107194  -0.060931    0.202356   735.75090   \n",
       " 0.365441   0.440359   0.506618   0.000000  -0.038395   -0.015463   838.49817   \n",
       " 0.918767   0.725878   0.383719   0.069215   0.492643    0.327247   798.20514   \n",
       " 0.411681   0.119499   0.904328  -0.077774  -0.501194    0.047105   818.75460   \n",
       " 1.432752   1.040896   0.488659   0.405288   0.503926    1.185380   769.59705   \n",
       " 0.718750   0.397905  -0.008378  -0.060147  -0.102181   -0.022893   800.21980   \n",
       " 0.487070   0.586418   0.292501   0.000000  -0.499837    0.222037   756.30035   \n",
       " 0.056968   0.975156   0.650653   0.488998   0.154784    0.828874   801.02563   \n",
       " 0.357012   0.632563   0.264747  -0.074426  -0.319983    0.058731   784.10254   \n",
       " 0.487026   0.574950   0.247701   0.000000   0.000000    0.261872   795.78754   \n",
       " 0.663098   0.528057   0.419827  -0.009557   0.083650    0.441265   781.28204   \n",
       " 0.526629   0.259321   0.078668  -0.781721  -0.118701    0.073226   805.86080   \n",
       " 0.531769   1.000487   1.514561  -0.355864   0.054773    1.180761   830.43960   \n",
       " 0.225120   0.898597   0.436874   0.643182  -0.230484    0.776700   803.04030   \n",
       " 0.481116   0.321507   0.762541   0.000000  -0.169691    0.261460   444.83517   \n",
       " 0.230538   0.185001   0.120361  -0.413380  -0.331284    0.073858   811.09890   \n",
       " 0.389395   0.651823   0.411299  -0.171896   0.148351    0.290528   788.13190   \n",
       "-3.568150  -2.936960  -2.995833   0.260758   0.322511   -3.177581  1606.48350   \n",
       " 0.081728   0.431461   0.555326  -0.184453   0.197267    0.499843   800.62270   \n",
       " 0.111698   0.930837   0.287210   0.417403   0.528995    0.963639   766.37360   \n",
       "...              ...        ...        ...        ...         ...         ...   \n",
       " 0.878025   0.700844   0.310464   0.549019   0.104566    0.291018   792.56410   \n",
       " 0.921296   0.616764   0.382557   0.000000  -0.038395    0.304299   929.96340   \n",
       " 0.877619   1.130002   0.141631  -0.130767  -0.253356    0.334861   809.89014   \n",
       "-0.404254   0.784826   0.184192   0.975612   0.350049    0.567323   740.98900   \n",
       " 0.048582   0.943477   0.066368   0.645398   0.443999    0.330189   832.45420   \n",
       " 1.050515   0.589225   0.001331  -0.480640  -0.698967    0.308598   782.89380   \n",
       " 0.818705   0.943796   1.279114  -0.481174  -0.478908    0.969057   786.11720   \n",
       " 0.733242   0.331940   0.383989  -0.781721  -0.140249    0.030793   794.57874   \n",
       "-3.568150  -2.936960  -2.995833   0.505250   0.550919   -3.177581  1430.00000   \n",
       " 0.543511   0.630488   0.366140  -0.187385   0.166574    0.355711   819.56040   \n",
       " 0.578504   1.019573   0.904326  -0.124254  -0.167107    0.622729   808.68134   \n",
       " 1.140964   0.891544   0.646883   0.564142   0.050763    0.479454   586.66670   \n",
       " 0.501428   0.648795   0.508110   0.929696  -0.482927    0.270117   794.57874   \n",
       " 0.826584   0.581531   0.199958   0.878257  -0.321140    0.472405   803.04030   \n",
       "-0.283943   0.716345   0.012694   0.000000   0.000000    0.339731   791.75824   \n",
       " 0.137270   0.885163   0.342910  -0.075824  -0.006954    0.386288   724.06590   \n",
       " 0.480742   0.694956   0.446513   0.810262   0.425074    0.499693   869.92676   \n",
       " 0.834978   0.572320   0.949144   0.929696  -0.341732    0.004771   758.71796   \n",
       "-0.032912   0.860762   0.962885   0.929696  -0.075575    0.736831   823.99270   \n",
       " 0.416303   0.552298   0.536953  -0.052702   0.323461    0.354430   799.81683   \n",
       " 0.737815   0.778927   0.346570   0.929696  -0.399023    0.461160   798.60803   \n",
       "-0.085366   0.438477   0.785193   0.000000  -0.169691    0.375424   783.29670   \n",
       " 0.257929   0.574186   0.056651   0.000000   0.000000    0.374387   790.54944   \n",
       " 0.451732   0.634369   0.857738   0.000000   0.031477    0.196273   902.96704   \n",
       " 0.553063   0.586484   0.349433   0.099045   0.164682    0.241952   803.44324   \n",
       "-0.094362   0.352823   0.206953  -0.554928   0.434432    0.242781   807.47253   \n",
       " 0.432693   0.582944   0.744184   0.000000  -0.180695    0.487011   643.88280   \n",
       " 0.446872   0.427456   0.198055   0.000000  -0.269374   -0.006804   765.97070   \n",
       "-3.198223   0.528602  -2.644557  -0.203229   0.033799    0.259945   678.13190   \n",
       " 0.580014   0.592762   0.265791  -0.442767  -0.269060    0.281754   823.58970   \n",
       "\n",
       "              RAW_AF7     RAW_AF8    RAW_TP10  \n",
       "Delta_TP9                                      \n",
       " 0.540034   866.30035   806.66670   865.09155  \n",
       " 0.149771   747.83880   780.47620   790.14655  \n",
       "-0.066366   788.93774   781.28204   821.57510  \n",
       " 0.218026  1130.21970  1031.50180   793.36993  \n",
       " 0.971143   784.10254   802.63740   786.11720  \n",
       " 0.676671   915.86080   761.53845   832.85710  \n",
       " 0.213173   862.67400   890.07324   800.62270  \n",
       " 0.323069   780.47620   794.98170   796.99634  \n",
       " 0.963676   809.89014   801.02563   799.81683  \n",
       " 1.318964   806.66670   795.78754   844.54210  \n",
       "-3.198223   741.39197   776.44690   364.65200  \n",
       " 0.365441   581.42860   721.24540   765.97070  \n",
       " 0.918767   775.23810   782.89380   780.07324  \n",
       " 0.411681   795.78754   809.48720   808.27840  \n",
       " 1.432752   804.65204   799.01100   761.94140  \n",
       " 0.718750   840.91580   802.23444   794.57874  \n",
       " 0.487070   936.81320   805.86080   743.80950  \n",
       " 0.056968   786.11720   790.54944   810.69600  \n",
       " 0.357012   790.14655   804.65204   792.56410  \n",
       " 0.487026  1018.60803  1015.78754   807.87550  \n",
       " 0.663098   795.38464   796.99634   796.19050  \n",
       " 0.526629   908.20514   799.41394   822.78390  \n",
       " 0.531769   805.86080   782.49084   788.53480  \n",
       " 0.225120   803.44324   802.63740   819.15753  \n",
       " 0.481116     0.00000   849.78020   514.13920  \n",
       " 0.230538   808.27840   777.65570   790.14655  \n",
       " 0.389395   788.93774   791.75824   802.63740  \n",
       "-3.568150   790.54944   714.79850     0.00000  \n",
       " 0.081728   781.28204   801.83150   777.65570  \n",
       " 0.111698   809.48720   791.75824   776.44690  \n",
       "...               ...         ...         ...  \n",
       " 0.878025   815.93410   799.81683   792.16120  \n",
       " 0.921296  1330.07320   661.61170   943.26010  \n",
       " 0.877619   798.20514   810.29300   783.29670  \n",
       "-0.404254   884.02930   797.80220   722.45420  \n",
       " 0.048582   785.31134   787.32600   839.30400  \n",
       " 1.050515   798.20514   804.65204   808.27840  \n",
       " 0.818705   788.13190   798.20514   789.74360  \n",
       " 0.733242   750.25640   840.51280   803.84610  \n",
       "-3.568150   784.90845   786.11720  1283.73620  \n",
       " 0.543511   794.17584   800.21980   824.39560  \n",
       " 0.578504   804.24910   791.35530   803.04030  \n",
       " 1.140964   795.38464   821.57510   799.41394  \n",
       " 0.501428  1082.27110   796.19050   802.23444  \n",
       " 0.826584   811.50183   795.38464   809.08420  \n",
       "-0.283943  1163.26010  1006.52014   794.57874  \n",
       " 0.137270   738.97437   847.76556   776.04395  \n",
       " 0.480742   824.79850   823.99270   882.41760  \n",
       " 0.834978   751.86810   816.33700   762.74725  \n",
       "-0.032912   860.65936   804.24910   821.57510  \n",
       " 0.416303   798.20514   790.54944   784.90845  \n",
       " 0.737815   921.50183   800.21980   807.87550  \n",
       "-0.085366   996.04395   956.55676   800.21980  \n",
       " 0.257929  1098.38830  1058.09520   787.32600  \n",
       " 0.451732  1257.14280   792.96704   814.32230  \n",
       " 0.553063   801.83150   772.82050   808.27840  \n",
       "-0.094362   667.65570   743.40660   801.42860  \n",
       " 0.432693     0.00000   801.02563   484.32236  \n",
       " 0.446872   639.85345   797.80220   760.73260  \n",
       "-3.198223   850.98900   718.82780   696.26373  \n",
       " 0.580014   808.68134   799.81683   832.05130  \n",
       "\n",
       "[11540 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:,:-1]\n",
    "# X = X.fillna(X.mean())\n",
    "# # np.where(np.isnan(X))\n",
    "normalized_X = preprocessing.normalize(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04346345  0.04078229  0.04488434  0.04307175  0.03723157  0.03720672\n",
      "  0.03961191  0.04609336  0.04357345  0.03796767  0.04108007  0.05241387\n",
      "  0.0553812   0.05056608  0.0485088   0.05936214  0.05269056  0.04946337\n",
      "  0.06024203  0.02854403  0.03280145  0.02960317  0.02545671]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAawAAAD8CAYAAAArMZDvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+kwsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22499f7ec50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,Y)\n",
    "print(model.feature_importances_)\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(17).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.296360485269\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_X, Y, test_size=0.3)\n",
    "model_5 = SVC(kernel='linear')\n",
    "model_5.fit(X_train, y_train)\n",
    "y_pred = model_5.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))\n",
    "# print(\"ROC-AUC Curve:\", roc_auc_score(y_test, y_pred))\n",
    "# print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.29116117851\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_X, Y, test_size=0.4)\n",
    "model_5 = SVC(kernel='linear')\n",
    "model_5.fit(X_train, y_train)\n",
    "y_pred = model_5.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))\n",
    "# print(\"ROC-AUC Curve:\", roc_auc_score(y_test, y_pred))\n",
    "# print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.295667244367\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_X, Y, test_size=0.5)\n",
    "model_5 = SVC(kernel='linear')\n",
    "model_5.fit(X_train, y_train)\n",
    "y_pred = model_5.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))\n",
    "# print(\"ROC-AUC Curve:\", roc_auc_score(y_test, y_pred))\n",
    "# print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.304159445407\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_X, Y, test_size=0.3)\n",
    "model_5 = SVC(kernel='linear')\n",
    "model_5.fit(X_train, y_train)\n",
    "y_pred = model_5.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))\n",
    "# print(\"ROC-AUC Curve:\", roc_auc_score(y_test, y_pred))\n",
    "# print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.304159445407\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_X, Y, test_size=0.3)\n",
    "model_5 = SVC(kernel='rbf')\n",
    "model_5.fit(X_train, y_train)\n",
    "y_pred = model_5.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))\n",
    "# print(\"ROC-AUC Curve:\", roc_auc_score(y_test, y_pred))\n",
    "# print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.301848642403\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_X, Y, test_size=0.3)\n",
    "model_5 = SVC(kernel='rbf')\n",
    "model_5.fit(X_train, y_train)\n",
    "y_pred = model_5.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))\n",
    "# print(\"ROC-AUC Curve:\", roc_auc_score(y_test, y_pred))\n",
    "# print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.29547141796585, total=   2.7s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.2955811362792425, total=   2.9s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    8.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.29580081753994797, total=   2.6s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV]  C=0.1, gamma=1, kernel=linear, score=0.29547141796585, total=   1.6s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV]  C=0.1, gamma=1, kernel=linear, score=0.2955811362792425, total=   1.6s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV]  C=0.1, gamma=1, kernel=linear, score=0.29580081753994797, total=   1.5s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.29547141796585, total=   2.5s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.2955811362792425, total=   2.5s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.29580081753994797, total=   2.5s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=linear, score=0.29547141796585, total=   1.5s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=linear, score=0.2955811362792425, total=   1.5s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=linear, score=0.29580081753994797, total=   1.6s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.29547141796585, total=   2.4s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.2955811362792425, total=   2.5s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.29580081753994797, total=   2.6s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=linear, score=0.29547141796585, total=   1.5s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=linear, score=0.2955811362792425, total=   1.5s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=linear, score=0.29580081753994797, total=   1.5s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.29547141796585, total=   2.5s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.2955811362792425, total=   2.9s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.29580081753994797, total=   2.5s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=linear, score=0.29547141796585, total=   1.7s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=linear, score=0.2955811362792425, total=   1.6s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=linear, score=0.29580081753994797, total=   1.8s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=0.29547141796585, total=   3.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=0.2955811362792425, total=   2.9s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=0.29580081753994797, total=   2.7s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=linear, score=0.29547141796585, total=   1.5s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=linear, score=0.2955811362792425, total=   1.5s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=linear, score=0.29580081753994797, total=   1.5s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] . C=1, gamma=1, kernel=rbf, score=0.29547141796585, total=   2.9s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV]  C=1, gamma=1, kernel=rbf, score=0.2955811362792425, total=   2.7s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV]  C=1, gamma=1, kernel=rbf, score=0.29580081753994797, total=   2.8s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV]  C=1, gamma=1, kernel=linear, score=0.29547141796585, total=   1.5s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV]  C=1, gamma=1, kernel=linear, score=0.2955811362792425, total=   1.9s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV]  C=1, gamma=1, kernel=linear, score=0.29580081753994797, total=   1.7s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.29547141796585, total=   2.5s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.2955811362792425, total=   2.8s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.29580081753994797, total=   2.6s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV]  C=1, gamma=0.1, kernel=linear, score=0.29547141796585, total=   1.8s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV]  C=1, gamma=0.1, kernel=linear, score=0.2955811362792425, total=   1.6s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV]  C=1, gamma=0.1, kernel=linear, score=0.29580081753994797, total=   1.6s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.29547141796585, total=   3.8s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.2955811362792425, total=   2.5s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.29580081753994797, total=   2.7s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV]  C=1, gamma=0.01, kernel=linear, score=0.29547141796585, total=   2.5s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV]  C=1, gamma=0.01, kernel=linear, score=0.2955811362792425, total=   1.8s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV]  C=1, gamma=0.01, kernel=linear, score=0.29580081753994797, total=   1.6s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.29547141796585, total=   2.4s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.2955811362792425, total=   2.5s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.29580081753994797, total=   2.7s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV]  C=1, gamma=0.001, kernel=linear, score=0.29547141796585, total=   2.1s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV]  C=1, gamma=0.001, kernel=linear, score=0.2955811362792425, total=   1.7s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV]  C=1, gamma=0.001, kernel=linear, score=0.29580081753994797, total=   1.6s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.29547141796585, total=   2.8s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.2955811362792425, total=   2.6s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.29580081753994797, total=   3.1s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=linear, score=0.29547141796585, total=   1.7s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1, gamma=0.0001, kernel=linear, score=0.2955811362792425, total=   1.9s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=linear, score=0.29580081753994797, total=   2.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.2951002227171492, total=   3.7s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.2955811362792425, total=   3.6s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.29580081753994797, total=   3.5s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV]  C=10, gamma=1, kernel=linear, score=0.29547141796585, total=   2.0s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV]  C=10, gamma=1, kernel=linear, score=0.2955811362792425, total=   1.8s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV]  C=10, gamma=1, kernel=linear, score=0.29580081753994797, total=   1.9s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.29547141796585, total=   2.9s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.2955811362792425, total=   3.9s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.29580081753994797, total=   3.0s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV]  C=10, gamma=0.1, kernel=linear, score=0.29547141796585, total=   2.4s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV]  C=10, gamma=0.1, kernel=linear, score=0.2955811362792425, total=   2.3s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV]  C=10, gamma=0.1, kernel=linear, score=0.29580081753994797, total=   2.4s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV]  C=10, gamma=0.01, kernel=rbf, score=0.29547141796585, total=   2.8s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV]  C=10, gamma=0.01, kernel=rbf, score=0.2955811362792425, total=   2.5s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV]  C=10, gamma=0.01, kernel=rbf, score=0.29580081753994797, total=   2.5s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV]  C=10, gamma=0.01, kernel=linear, score=0.29547141796585, total=   1.8s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV]  C=10, gamma=0.01, kernel=linear, score=0.2955811362792425, total=   1.8s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV]  C=10, gamma=0.01, kernel=linear, score=0.29580081753994797, total=   1.9s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.29547141796585, total=   2.4s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.2955811362792425, total=   2.5s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.29580081753994797, total=   2.5s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV]  C=10, gamma=0.001, kernel=linear, score=0.29547141796585, total=   1.8s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV]  C=10, gamma=0.001, kernel=linear, score=0.2955811362792425, total=   1.8s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV]  C=10, gamma=0.001, kernel=linear, score=0.29580081753994797, total=   1.9s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.29547141796585, total=   2.5s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.2955811362792425, total=   3.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.29580081753994797, total=   2.8s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
      "[CV]  C=10, gamma=0.0001, kernel=linear, score=0.29547141796585, total=   1.9s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
      "[CV]  C=10, gamma=0.0001, kernel=linear, score=0.2955811362792425, total=   1.8s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
      "[CV]  C=10, gamma=0.0001, kernel=linear, score=0.29580081753994797, total=   1.9s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=100, gamma=1, kernel=rbf, score=0.2951002227171492, total=   7.5s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=100, gamma=1, kernel=rbf, score=0.2955811362792425, total=  10.2s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=100, gamma=1, kernel=rbf, score=0.29580081753994797, total=  10.1s\n",
      "[CV] C=100, gamma=1, kernel=linear ...................................\n",
      "[CV]  C=100, gamma=1, kernel=linear, score=0.29547141796585, total=   4.4s\n",
      "[CV] C=100, gamma=1, kernel=linear ...................................\n",
      "[CV]  C=100, gamma=1, kernel=linear, score=0.2955811362792425, total=   3.8s\n",
      "[CV] C=100, gamma=1, kernel=linear ...................................\n",
      "[CV]  C=100, gamma=1, kernel=linear, score=0.29580081753994797, total=   4.3s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=100, gamma=0.1, kernel=rbf, score=0.29547141796585, total=   4.6s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=100, gamma=0.1, kernel=rbf, score=0.2955811362792425, total=   4.4s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=100, gamma=0.1, kernel=rbf, score=0.29580081753994797, total=   3.8s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
      "[CV]  C=100, gamma=0.1, kernel=linear, score=0.29547141796585, total=   4.1s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
      "[CV]  C=100, gamma=0.1, kernel=linear, score=0.2955811362792425, total=   4.1s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
      "[CV]  C=100, gamma=0.1, kernel=linear, score=0.29580081753994797, total=   4.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=100, gamma=0.01, kernel=rbf, score=0.29547141796585, total=   2.7s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=100, gamma=0.01, kernel=rbf, score=0.2955811362792425, total=   2.7s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=100, gamma=0.01, kernel=rbf, score=0.29580081753994797, total=   2.8s\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
      "[CV]  C=100, gamma=0.01, kernel=linear, score=0.29547141796585, total=   3.8s\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
      "[CV]  C=100, gamma=0.01, kernel=linear, score=0.2955811362792425, total=   4.0s\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
      "[CV]  C=100, gamma=0.01, kernel=linear, score=0.29580081753994797, total=   4.2s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.29547141796585, total=   2.9s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.2955811362792425, total=   3.3s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.29580081753994797, total=   2.8s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV]  C=100, gamma=0.001, kernel=linear, score=0.29547141796585, total=   4.0s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV]  C=100, gamma=0.001, kernel=linear, score=0.2955811362792425, total=   3.7s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV]  C=100, gamma=0.001, kernel=linear, score=0.29580081753994797, total=   4.1s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.29547141796585, total=   2.5s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.2955811362792425, total=   2.6s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.29580081753994797, total=   2.5s\n",
      "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
      "[CV]  C=100, gamma=0.0001, kernel=linear, score=0.29547141796585, total=   3.9s\n",
      "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
      "[CV]  C=100, gamma=0.0001, kernel=linear, score=0.2955811362792425, total=   3.9s\n",
      "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
      "[CV]  C=100, gamma=0.0001, kernel=linear, score=0.29580081753994797, total=   4.2s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV]  C=1000, gamma=1, kernel=rbf, score=0.29398663697104677, total=  25.9s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV]  C=1000, gamma=1, kernel=rbf, score=0.2952098031934645, total=  26.5s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV]  C=1000, gamma=1, kernel=rbf, score=0.2954292084726867, total=  26.4s\n",
      "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
      "[CV]  C=1000, gamma=1, kernel=linear, score=0.29547141796585, total=  48.6s\n",
      "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
      "[CV]  C=1000, gamma=1, kernel=linear, score=0.2955811362792425, total=  39.0s\n",
      "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
      "[CV]  C=1000, gamma=1, kernel=linear, score=0.29580081753994797, total=  42.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=rbf, score=0.29547141796585, total=  10.5s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=rbf, score=0.2955811362792425, total=  11.2s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=rbf, score=0.29580081753994797, total=  11.1s\n",
      "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=linear, score=0.29547141796585, total=  49.8s\n",
      "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=linear, score=0.2955811362792425, total=  38.9s\n",
      "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=linear, score=0.29580081753994797, total=  43.4s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=1000, gamma=0.01, kernel=rbf, score=0.29547141796585, total=   4.6s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=1000, gamma=0.01, kernel=rbf, score=0.2955811362792425, total=   4.7s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=1000, gamma=0.01, kernel=rbf, score=0.29580081753994797, total=   4.8s\n",
      "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
      "[CV]  C=1000, gamma=0.01, kernel=linear, score=0.29547141796585, total=  47.1s\n",
      "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
      "[CV]  C=1000, gamma=0.01, kernel=linear, score=0.2955811362792425, total=  36.6s\n",
      "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
      "[CV]  C=1000, gamma=0.01, kernel=linear, score=0.29580081753994797, total=  41.4s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.29547141796585, total=   3.4s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.2955811362792425, total=   3.1s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.29580081753994797, total=   3.2s\n",
      "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
      "[CV]  C=1000, gamma=0.001, kernel=linear, score=0.29547141796585, total=  44.7s\n",
      "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
      "[CV]  C=1000, gamma=0.001, kernel=linear, score=0.2955811362792425, total=  37.8s\n",
      "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
      "[CV]  C=1000, gamma=0.001, kernel=linear, score=0.29580081753994797, total=  40.7s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.29547141796585, total=   2.7s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.2955811362792425, total=   2.8s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.29580081753994797, total=   2.8s\n",
      "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=linear, score=0.29547141796585, total=  42.8s\n",
      "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=linear, score=0.2955811362792425, total=  36.5s\n",
      "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=linear, score=0.29580081753994797, total=  40.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed: 21.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['rbf', 'linear']}  \n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train) \n",
    "\n",
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "print(grid.best_estimator_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
